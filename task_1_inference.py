import torch
import numpy as np
import cv2
import os
from pathlib import Path
import random
import sys
import argparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π
PROJECT_ROOT = Path(__file__).parent
#print(PROJECT_ROOT)
RAFT_DIR = PROJECT_ROOT / "RAFT-Stereo"
core_path = RAFT_DIR / "core"
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(core_path))
sys.path.insert(0, str(RAFT_DIR))

# –ò–º–ø–æ—Ä—Ç—ã
from raft_stereo import RAFTStereo
from utils.utils import InputPadder

# –ò–º–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
from stereo_datasets import StereoDataset


# ================== –ù–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è InStereo2K Sample ==================
class InStereo2KSample(StereoDataset):
    def __init__(self, root, is_test=True):
        super(InStereo2KSample, self).__init__()
        self.root = root
        self.is_test = True  # –í—Å–µ–≥–¥–∞ –≤ —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

        # –ù–∞–π–¥–µ–º –≤—Å–µ –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
        folders = sorted([f for f in Path(root).iterdir() if f.is_dir()])

        self.image_list = []
        self.disparity_list = []

        for folder in folders:
            left_path = folder / "left.png"
            right_path = folder / "right.png"
            disp_path = folder / "left_disp.png"  # –∏–ª–∏ "right_disp.png"

            if left_path.exists() and right_path.exists():
                self.image_list.append([str(left_path), str(right_path)])
                self.disparity_list.append(str(disp_path))
                self.extra_info.append(str(folder.name))

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(self.image_list)} —Å—Ç–µ—Ä–µ–æ-–ø–∞—Ä")


# ================== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ==================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DATA_DIR = r"dl-cv-home-test-master\data\instereo2k_sample"
OUT_DIR = "results/1st_task_disparity_instereo2k_sample"
MODEL_PATH = "RAFT-Stereo/models/raftstereo-middlebury.pth"

os.makedirs(OUT_DIR, exist_ok=True)


# ================== –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ==================
class Args:
    def __init__(self):
        self.hidden_dims = [128] * 3
        self.corr_implementation = "reg"
        self.shared_backbone = False
        self.corr_levels = 4
        self.corr_radius = 4
        self.n_downsample = 2
        self.context_norm = "batch"
        self.slow_fast_gru = False
        self.n_gru_layers = 3
        self.mixed_precision = False


# ================== –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ==================
def load_model():
    args = Args()
    model = RAFTStereo(args)

    if os.path.exists(MODEL_PATH):
        print(f"–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –∏–∑: {MODEL_PATH}")
        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ DataParallel
        if 'module.' in list(checkpoint.keys())[0]:
            new_checkpoint = {}
            for key, value in checkpoint.items():
                new_key = key.replace('module.', '')
                new_checkpoint[new_key] = value
            checkpoint = new_checkpoint

        model.load_state_dict(checkpoint, strict=False)
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    else:
        print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL_PATH}")
        return None

    model = model.to(DEVICE)
    model.eval()
    return model


# ================== –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ==================
@torch.no_grad()
def run_inference(model, left_img, right_img, iters=32):
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã
    left_tensor = torch.from_numpy(left_img).permute(2, 0, 1).float()[None].to(DEVICE)
    right_tensor = torch.from_numpy(right_img).permute(2, 0, 1).float()[None].to(DEVICE)

    # Padding
    padder = InputPadder(left_tensor.shape, divis_by=32)
    left_pad, right_pad = padder.pad(left_tensor, right_tensor)

    # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
    use_mixed_precision = True
    with torch.cuda.amp.autocast(enabled=use_mixed_precision):
        _, flow_pr = model(left_pad, right_pad, iters=iters, test_mode=True)

    # –£–±–∏—Ä–∞–µ–º padding
    flow_pr = padder.unpad(flow_pr).cpu().squeeze(0)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∏—Å–ø–∞—Ä–∏—Ç–µ—Ç (–ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª)
    disparity = flow_pr[0].numpy()
    return disparity


# ================== –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏==================
'''def visualize_disparity_colormap(disparity_map, save_name):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ä—Ç—ã –¥–∏—Å–ø–∞—Ä–∏—Ç–µ—Ç–∞"""
    print(f"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏—Å–ø–∞—Ä–∏—Ç–µ—Ç–∞ –¥–ª—è: {save_name}")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω: {disparity_map.min():.4f} - {disparity_map.max():.4f}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ: {disparity_map.mean():.4f}")
    print(f"–ù—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {(disparity_map == 0).sum()} –∏–∑ {disparity_map.size}")

    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å —Ç—Ä–µ–º—è –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    plt.figure(figsize=(18, 5))

    # 1. –ò—Å—Ö–æ–¥–Ω–∞—è –∫–∞—Ä—Ç–∞ –¥–∏—Å–ø–∞—Ä–∏—Ç–µ—Ç–∞ —Å —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º–æ–π 'plasma'
    plt.subplot(1, 2, 1)
    plt.imshow(disparity_map, cmap='plasma')
    plt.colorbar(label='Disparity (raw)')
    plt.title('Raw Disparity Map')

    # 2. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∑–Ω–∞—á–µ–Ω–∏–π
    plt.subplot(1, 2, 2)
    plt.hist(disparity_map.flatten(), bins=100, alpha=0.7)
    plt.xlabel('Disparity Value')
    plt.ylabel('Frequency')
    plt.title('Disparity Distribution')
    plt.yscale('log')

    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    #save_path = os.path.join(OUT_DIR, f"{save_name}_analysis.png")
    #plt.savefig(save_path, dpi=150, bbox_inches='tight')
    #plt.close()
    #print(f"üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")'''


def save_disparity(disparity, save_name):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ disparity map –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ –º–µ—Ç–∫–∏"""

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs(OUT_DIR, exist_ok=True)

    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ .png —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (KITTI-style)
    disparity_uint16 = (disparity * 256).astype(np.uint16)
    cv2.imwrite(os.path.join(OUT_DIR, f"{save_name}.png"), disparity_uint16)

    #disp_vis = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX)
    #disp_vis = disp_vis.astype(np.uint8)
    #cv2.imwrite(os.path.join(OUT_DIR, f"{save_name}_vis.png"), disp_vis)

    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_name} (.png)")

# ================== –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ==================
def main():
    print("=== –ò–Ω—Ñ–µ—Ä–µ–Ω—Å RAFT-Stereo –Ω–∞ InStereo2K Sample ===")

    # ================== –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ==================
    parser = argparse.ArgumentParser(description='–ò–Ω—Ñ–µ—Ä–µ–Ω—Å RAFT-Stereo –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ')
    parser.add_argument('--mode', choices=['random', 'all', 'first'],
                        default='random', help='–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--count', type=int, default=10,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤ (–¥–ª—è random/first)')
    args = parser.parse_args()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_model()
    if model is None:
        return

    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = InStereo2KSample(DATA_DIR, is_test=True)
    total_samples = len(dataset)
    print(f"–í—Å–µ–≥–æ –ø–∞—Ä –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {total_samples}")

    if total_samples == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return

    # ================== –í—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ ==================
    if args.mode == 'all':
        indices = list(range(total_samples))
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(indices)} —Å—ç–º–ø–ª–æ–≤")
    elif args.mode == 'random':
        count = min(args.count, total_samples)
        indices = random.sample(range(total_samples), count)
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {count} —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤")
    elif args.mode == 'first':
        count = min(args.count, total_samples)
        indices = list(range(count))
        print(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–≤—ã—Ö {count} —Å—ç–º–ø–ª–æ–≤')

    # ================== –û–±—Ä–∞–±–æ—Ç–∫–∞ ==================
    print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(indices)} —Å—ç–º–ø–ª–æ–≤...")

    successful = 0
    failed = 0

    for i, idx in enumerate(indices):
        print(f"\n[{i + 1}/{len(indices)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ {idx}...")

        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            left_tensor, right_tensor, folder_name = dataset[idx]

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –≤ numpy
            left_img = left_tensor.permute(1, 2, 0).numpy().astype(np.uint8)
            right_img = right_tensor.permute(1, 2, 0).numpy().astype(np.uint8)

            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            disparity = run_inference(model, left_img, right_img)
            save_disparity(disparity, f"{folder_name}_{idx}")
            successful += 1

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–Ω–¥–µ–∫—Å–∞ {idx}: {e}")
            import traceback
            traceback.print_exc()
            failed += 1
            continue

    print(f"\n‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print(f"   –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"   –û—à–∏–±–æ–∫:  {failed}")
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUT_DIR}")


if __name__ == "__main__":
    main()